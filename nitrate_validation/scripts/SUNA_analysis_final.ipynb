{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a8c167-b151-48b4-b610-6fbfe1c9077d",
   "metadata": {},
   "source": [
    "# A 5-year validated Nitrate Dataset from the Pioneer-NES array\n",
    "\n",
    "The Ocean Observatories Initiative (OOI) deployed both the In-Situ Ultraviolet Spectrophotometer (ISUS) and Submersible Underwater Nitrate Sensor (SUNA) for continuous, in-situ measurement of nitrate. At the Pioneer-New England Shelf Array (Pioneer-NES), ISUS/SUNA sensors were deployed at 7-meters depth at the Inshore (ISSM), Central (CNSM), and Offshore (OSSM) Surface Mooring locations. The SUNA sensor replaced the ISUS sensors spring 2018. The SUNA was a major improvement in technology, with significant improvements in accuracy and precision. However, it still suffers from calibration drift due to lamp fatigue and biofouling as well as spectral interference due to bromide and fluorometric CDOM. \n",
    "\n",
    "This notebook implements the recommendations from the _OOI Biogeochemical Sensor Data: Best Practices and User Guide_ for correcting and validating the SUNA Data. Drift is corrected by application of post-cruise calibrations to recalculate the temperature-and-salinity corrected nitrate concentration following Sakamoto (2009a) and estimating a linear drift between pre-and-post cruise deployments. Validation is performed by comparison with discrete water samples collected during deployment/recovery of the sensors, with correction for offsets and drift due to biofouling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a6d41-bf22-4664-82b1-d6b805f6ad99",
   "metadata": {},
   "source": [
    "#### Load Libraries\n",
    "\n",
    "This notebook makes extensive use of  OOI-developed python libraries: ```ooi_data_explorations```. This is availble on gitHub with instructions for setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee261456-a6cd-4091-959a-613b50631430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Load ooi_data_explorations toolset\n",
    "from ooi_data_explorations.common import get_annotations, get_vocabulary, load_kdata, add_annotation_qc_flags,  get_deployment_dates, list_deployments, get_sensor_information\n",
    "from ooi_data_explorations.combine_data import combine_datasets\n",
    "from ooi_data_explorations.uncabled.process_nutnr import suna_datalogger, suna_instrument, drift_correction\n",
    "from ooi_data_explorations.bottles import clean_data\n",
    "\n",
    "# Import the utils/functions\n",
    "from utils import *\n",
    "\n",
    "# Matplotlib for plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a911f-97eb-4872-8000-444dfe7014a5",
   "metadata": {},
   "source": [
    "---\n",
    "## Datasets\n",
    "\n",
    "SUNA datasets are known as “NUTNR” on OOI (Nutrient Sensor). NUTNR datasets predating spring 2018 are from the ISUS instrument and not used, due to known measurement issues that make a quantitative data quality assessment difficult. SUNA datasets at the Pioneer-NES array begin with deployment 9 for CNSM and deployment 8 for both ISSM and OSSM. SUNA datasets from the three moorings cover from March 2018 through November 2022, when the Pioneer-NES array was retired.\n",
    "\n",
    "The SUNA datasets are downloaded on a deployment-by-deployment basis. Each dataset additionally contains the practical salinity and seawater temperature measured by the collocated CTD on the mooring NSIF. This data is interpolated to the SUNA dataset timestamps and integrated into the dataset by OOI. Salinity and temperature are necessary to calculate the Sakamoto (2009) nitrate correction for salinity interference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c93d77-e94b-4268-a27f-a90b35083a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "nes_datasets = pd.read_csv(\"../data/nes_datasets.csv\")\n",
    "nes_datasets['deployments'] = nes_datasets['deployments'].apply(ast.literal_eval)\n",
    "nes_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114eb204-016b-4787-88fb-173b85777ac6",
   "metadata": {},
   "source": [
    "### Load the SUNA Data\n",
    "\n",
    "The following steps are taken in order to download, and \n",
    "* Iterate through each individual deployment\n",
    "* For each deployment method (telemetered/recovered_host/recovered_inst) :\n",
    "    1. Load the dataset\n",
    "    2. Process the datasets\n",
    "    3. Run QC checks\n",
    "    4. Burst average using median averaging to 15-minute intervals\n",
    "* The average datasets are combined into a single \"merged\" dataset\n",
    "* Save the results to local data directory as \"_merged\"\n",
    "\n",
    "The following table outlines the relevant parameters in the dataset for the QC-checks that are performed:\n",
    "\n",
    "| Parameter\t| Suspect Threshold |\tFail Threshold |\n",
    "| --------- | ----------------- | -------------- |\n",
    "| RMSE of spectral fit\t| >0.001\t| >0.1| \n",
    "| Absorbance at 254 nm\t| N/A\t| >1.3| \n",
    "| Absorbance at 350 nm\t| N/A\t| >1.3| \n",
    "| Dark values\t| N/A\t| <0| \n",
    "| Spectrum average\t| N/A\t| <10000| \n",
    "| Nitrate concentration\t| N/A\t| <-2 or >3000| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552bf33-4b06-4573-8fb9-be4948e2c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the reference designator\n",
    "refdes = 'CP04OSSM-RID26-07-NUTNRB000'\n",
    "site, node, sensor = refdes.split(\"-\",2)\n",
    "\n",
    "# Get the deployments\n",
    "idx = nes_datasets[nes_datasets[\"array\"] == site].index\n",
    "deployments = nes_datasets.loc[idx[0]]['deployments']\n",
    "if 'CNSM' in site:\n",
    "    deployments = [x for x in deployments if x > 8]\n",
    "else:\n",
    "    deployments = [x for x in deployments if x >= 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d1640-fe26-435c-9a41-d19405109b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go deployment-by-deployment for the given reference designator, download the data from each delivery method\n",
    "# add annotations, process, burst-average the data, combine the methods, and save\n",
    "for dN in deployments:\n",
    "\n",
    "    # Get a single deployment dataset\n",
    "    dN = str(dN).zfill(4)\n",
    "\n",
    "    # Grab the annotations to later add to the datasets\n",
    "    annotations = get_annotations(site, node, sensor)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Load and process the Telemetered data\n",
    "    tdata = load_kdata(site, node, sensor, 'telemetered', 'suna_dcl_recovered', tag=f'deployment{dN}_{refdes}*.nc')\n",
    "    # Add in annotation qc flags to the \"unprocessed\" dataset\n",
    "    tdata = add_annotation_qc_flags(tdata, annotations)\n",
    "    # Now process the data\n",
    "    tdata = suna_datalogger(tdata, burst=False)\n",
    "    # Resample the data\n",
    "    tdata = burst_resample(tdata)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Load and process the Recovered host data\n",
    "    hdata = load_kdata(site, node, sensor, 'recovered_host', 'suna_dcl_recovered', tag=f'deployment{dN}_{refdes}*.nc')\n",
    "    # Add in annotation qc flags to the \"unprocessed\" dataset\n",
    "    hdata = add_annotation_qc_flags(hdata, annotations)\n",
    "    # Now process the data\n",
    "    hdata = suna_datalogger(hdata, burst=False)    # Resample the data\n",
    "    # Resample the data\n",
    "    hdata = burst_resample(hdata)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Load and process the Recovered instrument data\n",
    "    idata = load_kdata(site, node, sensor, 'recovered_inst', 'suna_instrument_recovered', tag=f'deployment{dN}_{refdes}*.nc')\n",
    "    # Add in annotation qc flags to the \"unprocessed\" dataset\n",
    "    idata = add_annotation_qc_flags(idata, annotations)\n",
    "    # Now process the data\n",
    "    idata = suna_instrument(idata, burst=False)\n",
    "    # Resample the data\n",
    "    idata = burst_resample(idata)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Combine the data\n",
    "    data = combine_datasets(tdata, hdata, idata, None)\n",
    "\n",
    "    # Remove the data that can't be serialized in a netCDF\n",
    "    del data['internal_timestamp'].attrs['calendar']\n",
    "    del data['internal_timestamp'].attrs['units']\n",
    "\n",
    "    # Save the merged dataset\n",
    "    array = site[4:]\n",
    "    data.to_netcdf(f\"../data/Pioneer-NES/{array}/{refdes}_deployment{dN}_merged.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec2555-e21d-454a-9617-5f1f39ee1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ooi_data_explorations.common import get_deployment_dates, list_deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca41f61-0035-4843-8851-4bbdf1042b66",
   "metadata": {},
   "source": [
    "### Apply the Drift Correction\n",
    "Drift in the observed nitrate is known to occur due to lamp aging and biofouling. The impact of lamp aging can be corrected for using a post-cruise calibration and calculating a linear change between the pre-and-post deployment calibrations following Palevsky et al (2023):\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta NO_{3}}{day} = \\frac{NO_{3}^{predeployment \\ cal} - NO_{3}^{postdeployment \\ cal}}{Predeployment \\ date - postdeployment \\ date}\n",
    "$$\n",
    "\n",
    "In practice, we don’t have the DI water dataset for the pre-and-post deployment calibrations, just the calibration files themselves. Instead, we recalculate the nitrate concentration timeseries using the post-deployment calibration and assume that the difference between the timeseries calculated with the pre-deployment calibration and post-deployment calibration at the start of the deployment is $\\Delta NO_{3}$. This assumption is reasonable because, apart from burn-in, the sensor is lightly used pre-deployment and drift due to lamp aging is a function of lamp-use.\n",
    "\n",
    "The procedure here is to:\n",
    "* Load each _merged dataset\n",
    "* Apply the drift correction\n",
    "* Save the corrected dataset as _drift_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff425ed-23b7-4474-9e71-1903ea707176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basepath = \"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES\"\n",
    "for mooring in os.listdir(basepath):\n",
    "    if not mooring.endswith('SM'):\n",
    "        continue\n",
    "    else:\n",
    "        mooringpath = \"/\".join((basepath, mooring))\n",
    "        for dataset in sorted(os.listdir(mooringpath)):\n",
    "            if dataset.endswith('_merged.nc'):\n",
    "                filepath = \"/\".join((mooringpath, dataset))\n",
    "                # Load the file\n",
    "                refdes = dataset.split(\"_\")[0]\n",
    "                subsite, node, sensor = refdes.split(\"-\", 2)\n",
    "                data = xr.open_dataset(filepath)\n",
    "                # Apply the drift correction\n",
    "                data = drift_correction(data, subsite, node, sensor)\n",
    "                # Save the results\n",
    "                dataset = dataset.replace(\"_merged\",\"_drift_corrected\")\n",
    "                new_filepath = \"/\".join((mooringpath, dataset))\n",
    "                data.to_netcdf(new_filepath, format=\"netcdf4\", engine='h5netcdf') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef76e1-3803-4a23-ab73-2c87e1af3015",
   "metadata": {},
   "source": [
    "### Merge Drift Corrected Datasets \n",
    "Now, we will merge all of the datasets which have had the drift correction applied for a given sensor and merge them into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06cc846-5a28-4c12-9700-72efb9b3579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES\"\n",
    "for mooring in os.listdir(basepath):\n",
    "    data = None\n",
    "    if not mooring.endswith('SM'):\n",
    "        continue\n",
    "    else:\n",
    "        mooringpath = \"/\".join((basepath, mooring))\n",
    "        for file in sorted(os.listdir(mooringpath)):\n",
    "            if \"drift\" in file:\n",
    "                ds = xr.open_dataset(mooringpath + \"/\" + file)\n",
    "                if data is None:\n",
    "                    data = ds\n",
    "                else:\n",
    "                    data = xr.concat([data, ds], dim=\"time\")\n",
    "    # Apply the quality checks on the drift-corrected nitrate\n",
    "    qc_flags = quality_checks(data, 'drift_corrected_nitrate')\n",
    "    data[\"drift_corrected_nitrate_qc_flag\"] = qc_flags\n",
    "    data[\"drift_corrected_nitrate_qc_flag\"].attrs = {\n",
    "        'flag_values': np.array([1, 2, 3, 4, 9]),\n",
    "        'flag_meanings': 'pass not_evaluated suspect_or_of_high_interest fail missing_data',\n",
    "        'standard_name': 'drift_corrected_nitrate status_flag',\n",
    "        'long_name': 'Nitrate Concentration - Temp, Sal, and Drift Corrected Quality Flag',\n",
    "        'comment': ('This quality flag represents an assessment of the nitrate concentration '\n",
    "                    'that is corrected for temperature, salinity following Sakamoto (2009), '\n",
    "                    'and for instrument drift. Checks include assessment of RMSE of the spectral '\n",
    "                    'measurements, absorptions at 254 nm and 350 nm wavelengths, dark values, '\n",
    "                    'spectral averages, and a range check based on instrument calibration.')\n",
    "    }\n",
    "    \n",
    "    # Update the drift corrected nitrate description\n",
    "    data['drift_corrected_nitrate'].attrs['comment'] = ('The measured nitrate concentration that is corrected for temperature '\n",
    "                'and salinity following Sakamoto (2009), with linear drift, estimated from the difference between pre-and-post cruise DI-water calibrations, removed.')\n",
    "\n",
    "    # Need to update the qc_flags on the T-S corrected nitrate concentration\n",
    "    qc_flags = quality_checks(data, 'corrected_nitrate_concentration')\n",
    "    data[\"corrected_nitrate_concentration_qc_flag\"] = qc_flags\n",
    "    data[\"corrected_nitrate_concentration_qc_flag\"].attrs = {\n",
    "        'flag_values': np.array([1, 2, 3, 4, 9]),\n",
    "        'flag_meanings': 'pass not_evaluated suspect_or_of_high_interest fail missing_data',\n",
    "        'standard_name': 'bottle_corrected_nitrate status_flag',\n",
    "        'long_name': 'Nitrate Concentration - Temp, Sal, and Drift Corrected Quality Flag',\n",
    "        'comment': ('This quality flag represents an assessment of the nitrate concentration '\n",
    "                    'that is corrected for temperature, salinity following Sakamoto (2009). '\n",
    "                    'Checks include assessment of RMSE of the spectral '\n",
    "                    'measurements, absorptions at 254 nm and 350 nm wavelengths, dark values, '\n",
    "                    'spectral averages, and a range check based on instrument calibration.')\n",
    "    }\n",
    "    \n",
    "    # Save the result\n",
    "    filename = filepath.split(\"/\")[-1].split(\"_\")[0]\n",
    "    savepath = mooringpath + \"/\" + filename + \".nc\"\n",
    "    data.to_netcdf(savepath, format=\"netcdf4\", engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471621d9-ca5e-4904-bb29-ccc3f2d893e9",
   "metadata": {},
   "source": [
    "### Load the processed and merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6fc1c-2a6f-4ecc-aaf1-186b4adfa25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnsm = xr.open_dataset(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/CNSM/CP01CNSM-RID26-07-NUTNRB000.nc\")\n",
    "ossm = xr.open_dataset(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/OSSM/CP01CNSM-RID26-07-NUTNRB000.nc\")\n",
    "issm = xr.open_dataset(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/ISSM/CP01CNSM-RID26-07-NUTNRB000.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48688006-dfa3-43f1-9e1a-eeb3da24a0b6",
   "metadata": {},
   "source": [
    "---\n",
    "## Bottle Correction\n",
    "One of the primary purposes of the discrete water sampling data is for the evaluation and validation of OOI instrumentation.  Following the methods described in Palevsky et al. (2023), we use the bottle data collected during deployment and recovery of the SUNA sensors to correct for offsets and drift. This is done with the following equation:\n",
    "\n",
    "$$\n",
    "\\frac{\\Delta NO_{3}}{day}=\\frac{(NO_{3}^{bottle}-NO_{3}^{SUNA})_{deployment}-(NO_{3}^{bottle}-NO_{3}^{SUNA})_{recovery}}{Recovery\\ date-deployment\\ date}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\Delta NO_{3}^{offset}=(NO_{3}^{bottle}-NO_{3}^{SUNA})_{deployment}\n",
    "$$\n",
    "\n",
    "which yields the following equation for calculating the bottle-adjusted nitrate:\n",
    "\n",
    "$$\n",
    "NO_{3}^{adj}(t)=NO_{3}^{obs}(t)+\\frac{\\Delta NO_{3}}{day}*\\Delta t+\\Delta NO_{3}^{offset}\n",
    "$$\n",
    "\n",
    "### Load and Clean the Bottle Data\n",
    "Next, we want to load and clean the bottle data for the Pioneer-NES array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1261b-d713-47b7-b91d-ca7d01362989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ooi_data_explorations.bottles import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e23cb-04bf-44d2-84c9-bfeb97baf4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/home/jovyan/ooi/cruise_data/pioneer-nes'\n",
    "bottle_data = None\n",
    "\n",
    "for cruise in sorted(os.listdir(basepath)):\n",
    "    # Find the bottle data\n",
    "    cruise_path = \"/\".join((basepath, cruise, \"Water_Sampling\"))\n",
    "    if os.path.exists(cruise_path):\n",
    "        discrete_file = [x for x in os.listdir(cruise_path) if x.endswith('Discrete_Summary.csv')]\n",
    "        if len(discrete_file) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            discrete_file = discrete_file[0]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Load the individual cruise discrete file\n",
    "    cruise_data = pd.read_csv(\"/\".join((cruise_path, discrete_file)), index_col=None)\n",
    "\n",
    "    # Merge into a single dataset\n",
    "    if bottle_data is None:\n",
    "        bottle_data = cruise_data\n",
    "    else:\n",
    "        bottle_data = pd.concat([bottle_data, cruise_data], ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25470094-6c2b-4608-840a-3ffa9e4576c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_data = clean_data(bottle_data)\n",
    "bottle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fe003-4d74-4352-a4c0-aa252a3b1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, the Data on the Raw Data Repo isn't sufficient to cover all of the time period, so will use other sheets I prepared independently\n",
    "cnsm_nitrate = pd.read_excel(\"../data/Pioneer-NES/Ship/CNSM_nitrate.xlsx\", index_col=0)\n",
    "issm_nitrate = pd.read_excel(\"../data/Pioneer-NES/Ship/ISSM_nitrate.xlsx\", index_col=0)\n",
    "ossm_nitrate = pd.read_excel(\"../data/Pioneer-NES/Ship/OSSM_nitrate.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149b969-28df-48b4-9be3-599606b4d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match deployment and recovery numbers for each buoy with the datasets\n",
    "def remove_last_letter(x):\n",
    "    if x.endswith(('A','B')):\n",
    "        x = x[0:-1]\n",
    "    else:\n",
    "        pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4bf28-7e5c-4839-b460-b4aae5581933",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnsm_nitrate['Cruise'] = cnsm_nitrate['Cruise'].apply(lambda x: remove_last_letter(x))\n",
    "issm_nitrate['Cruise'] = issm_nitrate['Cruise'].apply(lambda x: remove_last_letter(x))\n",
    "ossm_nitrate['Cruise'] = ossm_nitrate['Cruise'].apply(lambda x: remove_last_letter(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d0eee-5f36-4a2b-abb9-b23decbf2d36",
   "metadata": {},
   "source": [
    "### Apply Bottle Offsets\n",
    "This next section applies the bottle offsets to the nitrate data at the start of the deployment\n",
    "\n",
    "First, the timeseries is smoothed using a 6-hour centered rolling average to reduce noise while preserving daily nutrient cycling patterns. Then, the deployment and recovery bottle nitrate and smoothed SUNA nitrate are matched based on time. If there is no SUNA nitrate data available within 3 days of the bottle data at recovery, we do not calculate a drift based on the bottle data. Instead, we apply only the offset correction using the $\\Delta NO_{3}^{offset}$ value. Otherwise, we go ahead and calculate $\\frac{\\Delta NO_{3}}{day}$ and apply Eqn. 4.4 to arrive at our bottle-corrected nitrate $NO_{3}^{adj}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a06dc-b845-4180-85db-3bc7741af8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ooi_data_explorations.common import get_sensor_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674f24e-06d4-4d00-9998-f63623798075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deployment_info(site, node, sensor, deployments):\n",
    "    keys = ['deploymentNumber', 'uid', 'deployStart', 'deployEnd', 'deployCruise', 'recoverCruise']\n",
    "    deployInfo = {x: [] for x in keys}\n",
    "    for dN in deployments:\n",
    "        # Get the sensor info\n",
    "        sensorInfo = get_sensor_information(site, node, sensor, dN)\n",
    "    \n",
    "        # With the sensor info for a given deployment, get relevant data\n",
    "        assetUid = sensorInfo[0]['sensor']['uid']\n",
    "    \n",
    "        # Get deployment info\n",
    "        deployCruise = sensorInfo[0]['deployCruiseInfo']['uniqueCruiseIdentifier']\n",
    "        deployStart = sensorInfo[0]['eventStartTime']\n",
    "        deployStart = pd.to_datetime(convert_time(deployStart))\n",
    "    \n",
    "        # Get recovery info\n",
    "        recoverCruise = sensorInfo[0]['recoverCruiseInfo']['uniqueCruiseIdentifier']\n",
    "        deployEnd = sensorInfo[0]['eventStopTime']\n",
    "        deployEnd = pd.to_datetime(convert_time(deployEnd))\n",
    "    \n",
    "        # Save results\n",
    "        deployInfo['deploymentNumber'].append(int(dN))\n",
    "        deployInfo['uid'].append(assetUid)\n",
    "        deployInfo['deployStart'].append(deployStart)\n",
    "        deployInfo['deployEnd'].append(deployEnd)\n",
    "        deployInfo['deployCruise'].append(deployCruise)\n",
    "        deployInfo['recoverCruise'].append(recoverCruise)\n",
    "\n",
    "    return deployInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985c06e-4cf3-466e-8381-760aeeaf7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, it is easiest to do the operation on a deployment by deployment basis\n",
    "def bottle_correction(ds, deployments, bottle_data):\n",
    "    \"\"\"Apply the bottle correction to a dataset\"\"\"\n",
    "    # First, check that the deployments dataset index is set to the deploymentNumber\n",
    "    if not deployments.index.name == 'deploymentNumber':\n",
    "        deployments.set_index(keys='deploymentNumber', drop=True, inplace=True)\n",
    "\n",
    "    # Next, get the unique deployment number of the dataset\n",
    "    deployNum = np.unique(ds['deployment'])\n",
    "\n",
    "    # Get the deployment and recovery cruises\n",
    "    deployCruise = deployments.loc[deployNum]['deployCruise'].values[0]\n",
    "    recoverCruise = deployments.loc[deployNum]['recoverCruise'].values[0]\n",
    "    \n",
    "    # Select the associated nitrate data\n",
    "    deployBottles = bottle_data[bottle_data['Cruise'] == deployCruise].drop(columns='Cruise').groupby('Start Time [UTC]').mean()\n",
    "    recoverBottles = bottle_data[bottle_data['Cruise'] == recoverCruise].drop(columns='Cruise').groupby('Start Time [UTC]').mean()\n",
    "\n",
    "    # Next, filter the NUTNR data using a 6H rolling window\n",
    "    smoothed_data = ds['drift_corrected_nitrate'].to_dataframe().rolling('6H', center=True, closed='both').mean()\n",
    "    smoothed_data = xr.Dataset(smoothed_data)\n",
    "    \n",
    "    # Find the closest data point in the smoothed data to get the \n",
    "    deploy_NO3 = deployBottles.reset_index().mean()\n",
    "    suna_NO3 = smoothed_data.sel(time=deploy_NO3['Start Time [UTC]'], method='nearest')\n",
    "    \n",
    "    # Calculate the bottle offset\n",
    "    bottle_offset = deploy_NO3['Discrete Nitrate [uM]'] - suna_NO3['drift_corrected_nitrate'].data\n",
    "\n",
    "    # Now add the offset to the smoothed suna data and full suna drift-corrected\n",
    "    smoothed_data = smoothed_data + bottle_offset\n",
    "    \n",
    "    # With the data adjusted for the starting offset, calculate the difference at the end\n",
    "    recover_NO3 = recoverBottles.reset_index().mean()\n",
    "    suna_NO3 = smoothed_data.sel(time=recover_NO3['Start Time [UTC]'], method='nearest')\n",
    "\n",
    "    # Check if the time difference between the bottle sample and the identified nearest \n",
    "    # SUNA measurement exceeds 3 days, in which case ONLY apply the initial offset\n",
    "    if len(recoverBottles) == 0:\n",
    "        delta_NO3 = xr.DataArray(\n",
    "            data = np.zeros(np.shape(smoothed_data['time'])),\n",
    "            dims = 'time',\n",
    "            coords = dict(\n",
    "                time=smoothed_data.time)) \n",
    "    elif np.abs(suna_NO3['time'].values - recover_NO3['Start Time [UTC]']).to_timedelta64() > pd.Timedelta('3 days'):\n",
    "        delta_NO3 = xr.DataArray(\n",
    "            data = np.zeros(np.shape(smoothed_data['time'])),\n",
    "            dims = 'time',\n",
    "            coords = dict(\n",
    "                time=smoothed_data.time))   \n",
    "    else:\n",
    "        # Calculate the bottle-derived drift\n",
    "        dNO3 = recover_NO3['Discrete Nitrate [uM]'] - suna_NO3['drift_corrected_nitrate'].data\n",
    "        dt = recover_NO3['Start Time [UTC]'] - deploy_NO3['Start Time [UTC]']\n",
    "        dNO3_dt = dNO3/dt.to_timedelta64().astype('int')\n",
    "        delta_NO3 = (smoothed_data.time - np.datetime64(deploy_NO3['Start Time [UTC]'])).astype('int')*dNO3_dt\n",
    "\n",
    "    # Add in the bottle correction to both the smoothed data and the drift-corrected-data\n",
    "    smoothed_data = smoothed_data + delta_NO3\n",
    "    smoothed_data['deployment'] = ds['deployment']\n",
    "    ds['bottle_corrected_nitrate'] = ds['drift_corrected_nitrate'] + bottle_offset + delta_NO3\n",
    "    \n",
    "    return ds, smoothed_data, deployBottles, recoverBottles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f02ada-028f-4c8d-997e-9c9676095ef6",
   "metadata": {},
   "source": [
    "##### CP01CNSM-RID26-07-NUTNRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8e611-64bf-461c-a7b5-b74bf902eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the needed deployment information\n",
    "site, node, sensor = 'CP01CNSM-RID26-07-NUTNRB000'.split('-',2)\n",
    "deployInfo = get_deployment_info(site, node, sensor, deployments)\n",
    "deployInfo = pd.DataFrame(deployInfo)\n",
    "deployInfo.set_index(keys='deploymentNumber', drop=True, inplace=True)\n",
    "deployInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440db86f-99d9-459c-9f2c-82b5924cae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the bottle corrections to CNSM data\n",
    "new_cnsm = None\n",
    "smoothed_cnsm = None\n",
    "deploy_bottles = None\n",
    "recover_bottles = None\n",
    "for depNum in np.unique(cnsm['deployment']):\n",
    "    depdata = cnsm.where(cnsm.deployment == depNum, drop=True)\n",
    "    depdata, smoothed_data, deployBottles, recoverBottles = bottle_correction(depdata, deployInfo, cnsm_nitrate)\n",
    "    deployBottles['Deployment'] = depNum\n",
    "    recoverBottles['Deployment'] = depNum\n",
    "    if new_cnsm is None:\n",
    "        new_cnsm = depdata.copy(deep=True)\n",
    "        smoothed_cnsm = smoothed_data.copy(deep=True)\n",
    "        deploy_bottles = deployBottles\n",
    "        recover_bottles = recoverBottles\n",
    "    else:\n",
    "        new_cnsm = xr.concat([new_cnsm, depdata], dim='time')\n",
    "        smoothed_cnsm = xr.concat([smoothed_cnsm , smoothed_data], dim='time')\n",
    "        deploy_bottles = pd.concat([deploy_bottles, deployBottles])\n",
    "        recover_bottles = pd.concat([recover_bottles, recoverBottles])\n",
    "\n",
    "# Update the bottle corrected nitrate attributes\n",
    "new_cnsm['bottle_corrected_nitrate'].attrs = {\n",
    "    'long_name': 'Drift, Bottle, and T-S Corrected Dissolved Nitrate Concentration',\n",
    "    'standard_name': 'mole_concentration_of_nitrate_in_sea_water',\n",
    "    'units': 'umol L-1',\n",
    "    'comment': ('The measured nitrate concentration that is corrected for temperature '\n",
    "                'and salinity following Sakamoto (2009), '\n",
    "                'for instrument drift using pre- and post-deployment calibration, and '\n",
    "                'discrete water samples collected during deployment '\n",
    "                'and recovery.')\n",
    "}\n",
    "\n",
    "# Update and apply the quality checks on the drift-corrected nitrate\n",
    "qc_flags = quality_checks(new_cnsm, 'bottle_corrected_nitrate')\n",
    "new_cnsm[\"bottle_corrected_nitrate_qc_flag\"] = qc_flags\n",
    "new_cnsm[\"bottle_corrected_nitrate_qc_flag\"].attrs = {\n",
    "    'flag_values': np.array([1, 2, 3, 4, 9]),\n",
    "    'flag_meanings': 'pass not_evaluated suspect_or_of_high_interest fail missing_data',\n",
    "    'standard_name': 'bottle_corrected_nitrate status_flag',\n",
    "    'long_name': 'Nitrate Concentration - Temp, Sal, and Drift Corrected Quality Flag',\n",
    "    'comment': ('This quality flag represents an assessment of the nitrate concentration '\n",
    "                'that is corrected for temperature, salinity following Sakamoto (2009), '\n",
    "                'for instrument drift, and discrete water samples collected during deployment '\n",
    "                'and recovery. Checks include assessment of RMSE of the spectral '\n",
    "                'measurements, absorptions at 254 nm and 350 nm wavelengths, dark values, '\n",
    "                'spectral averages, and a range check based on instrument calibration.')\n",
    "}\n",
    "\n",
    "# Save the bottle values used for the corrections\n",
    "cnsm_deploy_bottles = deploy_bottles\n",
    "cnsm_recover_bottles = recover_bottles\n",
    "\n",
    "# Save the results\n",
    "cnsm.to_netcdf(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/CNSM/CP01CNSM-RID26-07-NUTNRB000_bottle_corrected.nc\", format='netcdf4', engine='h5netcdf')\n",
    "smoothed_cnsm.to_netcdf(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/CNSM/CP01CNSM-RID26-07-NUTNRB000_bottle_corrected_smoothed.nc\", format='netcdf4', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb9a97-483b-45c0-8b9f-76844ac3fab7",
   "metadata": {},
   "source": [
    "##### CP04OSSM-RID26-07-NUTNRB000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931a26f-585b-4fe0-9c42-bd41b3958fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the needed deployment information\n",
    "site, node, sensor = 'CP04OSSM-RID26-07-NUTNRB000'.split('-',2)\n",
    "deployInfo = get_deployment_info(site, node, sensor, deployments)\n",
    "deployInfo = pd.DataFrame(deployInfo)\n",
    "deployInfo.set_index(keys='deploymentNumber', drop=True, inplace=True)\n",
    "deployInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb47c5-162a-4100-a2b6-2a144dee305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ossm = None\n",
    "smoothed_ossm = None\n",
    "deploy_bottles = None\n",
    "recover_bottles = None\n",
    "for depNum in np.unique(ossm['deployment']):\n",
    "    depdata = ossm.where(ossm.deployment == depNum, drop=True)\n",
    "    depdata, smoothed_data, deployBottles, recoverBottles = bottle_correction(depdata, deployInfo, ossm_nitrate)\n",
    "    deployBottles['Deployment'] = depNum\n",
    "    recoverBottles['Deployment'] = depNum\n",
    "    if new_ossm is None:\n",
    "        new_ossm = depdata.copy(deep=True)\n",
    "        smoothed_ossm = smoothed_data.copy(deep=True)\n",
    "        deploy_bottles = deployBottles\n",
    "        recover_bottles = recoverBottles\n",
    "    else:\n",
    "        new_ossm = xr.concat([new_ossm, depdata], dim='time')\n",
    "        smoothed_ossm = xr.concat([smoothed_ossm , smoothed_data], dim='time')\n",
    "        deploy_bottles = pd.concat([deploy_bottles, deployBottles])\n",
    "        recover_bottles = pd.concat([recover_bottles, recoverBottles])\n",
    "\n",
    "# Update the bottle corrected nitrate attributes\n",
    "new_ossm['bottle_corrected_nitrate'].attrs = {\n",
    "    'long_name': 'Drift, Bottle, and T-S Corrected Dissolved Nitrate Concentration',\n",
    "    'standard_name': 'mole_concentration_of_nitrate_in_sea_water',\n",
    "    'units': 'umol L-1',\n",
    "    'comment': ('The measured nitrate concentration that is corrected for temperature '\n",
    "                'and salinity following Sakamoto (2009), '\n",
    "                'for instrument drift using pre- and post-deployment calibration, and '\n",
    "                'discrete water samples collected during deployment '\n",
    "                'and recovery.')\n",
    "}\n",
    "\n",
    "# Update and apply the quality checks on the drift-corrected nitrate\n",
    "qc_flags = quality_checks(new_ossm, 'bottle_corrected_nitrate')\n",
    "new_ossm[\"bottle_corrected_nitrate_qc_flag\"] = qc_flags\n",
    "new_ossm[\"bottle_corrected_nitrate_qc_flag\"].attrs = {\n",
    "    'flag_values': np.array([1, 2, 3, 4, 9]),\n",
    "    'flag_meanings': 'pass not_evaluated suspect_or_of_high_interest fail missing_data',\n",
    "    'standard_name': 'bottle_corrected_nitrate status_flag',\n",
    "    'long_name': 'Nitrate Concentration - Temp, Sal, and Drift Corrected Quality Flag',\n",
    "    'comment': ('This quality flag represents an assessment of the nitrate concentration '\n",
    "                'that is corrected for temperature, salinity following Sakamoto (2009), '\n",
    "                'for instrument drift, and discrete water samples collected during deployment '\n",
    "                'and recovery. Checks include assessment of RMSE of the spectral '\n",
    "                'measurements, absorptions at 254 nm and 350 nm wavelengths, dark values, '\n",
    "                'spectral averages, and a range check based on instrument calibration.')\n",
    "}\n",
    "\n",
    "# Save the bottle values used for the corrections\n",
    "ossm_deploy_bottles = deploy_bottles\n",
    "ossm_recover_bottles = recover_bottles\n",
    "\n",
    "# Save the results\n",
    "new_ossm.to_netcdf(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/OSSM/CP04OSSM-RID26-07-NUTNRB000_bottle_corrected.nc\", format='netcdf4', engine='h5netcdf')\n",
    "smoothed_ossm.to_netcdf(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/OSSM/CP04OSSM-RID26-07-NUTNRB000_bottle_corrected_smoothed.nc\", format='netcdf4', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901b07f-1f20-441a-86eb-b6982c33d14a",
   "metadata": {},
   "source": [
    "##### CP03ISSM-RID26-07-NUTNRB000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1e95a-ec70-47dd-844a-dcae4ed95f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the needed deployment information\n",
    "site, node, sensor = 'CP03ISSM-RID26-07-NUTNRB000'.split('-',2)\n",
    "deployInfo = get_deployment_info(site, node, sensor, deployments)\n",
    "deployInfo = pd.DataFrame(deployInfo)\n",
    "deployInfo.set_index(keys='deploymentNumber', drop=True, inplace=True)\n",
    "deployInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976844a-0fcb-4b43-b754-ab04a3d03afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_issm = None\n",
    "smoothed_issm = None\n",
    "deploy_bottles = None\n",
    "recover_bottles = None\n",
    "for depNum in np.unique(issm['deployment']):\n",
    "    depdata = issm.where(issm.deployment == depNum, drop=True)\n",
    "    depdata, smoothed_data, deployBottles, recoverBottles = bottle_correction(depdata, deployInfo, issm_nitrate)\n",
    "    deployBottles['Deployment'] = depNum\n",
    "    recoverBottles['Deployment'] = depNum\n",
    "    if new_issm is None:\n",
    "        new_issm = depdata.copy(deep=True)\n",
    "        smoothed_issm = smoothed_data.copy(deep=True)\n",
    "        deploy_bottles = deployBottles\n",
    "        recover_bottles = recoverBottles\n",
    "    else:\n",
    "        new_issm = xr.concat([new_issm, depdata], dim='time')\n",
    "        smoothed_issm = xr.concat([smoothed_issm , smoothed_data], dim='time')\n",
    "        deploy_bottles = pd.concat([deploy_bottles, deployBottles])\n",
    "        recover_bottles = pd.concat([recover_bottles, recoverBottles])\n",
    "\n",
    "# Update the bottle corrected nitrate attributes\n",
    "new_issm['bottle_corrected_nitrate'].attrs = {\n",
    "    'long_name': 'Drift, Bottle, and T-S Corrected Dissolved Nitrate Concentration',\n",
    "    'standard_name': 'mole_concentration_of_nitrate_in_sea_water',\n",
    "    'units': 'umol L-1',\n",
    "    'comment': ('The measured nitrate concentration that is corrected for temperature '\n",
    "                'and salinity following Sakamoto (2009), '\n",
    "                'for instrument drift using pre- and post-deployment calibration, and '\n",
    "                'discrete water samples collected during deployment '\n",
    "                'and recovery.')\n",
    "}\n",
    "\n",
    "# Update and apply the quality checks on the drift-corrected nitrate\n",
    "qc_flags = quality_checks(new_issm, 'bottle_corrected_nitrate')\n",
    "new_issm[\"bottle_corrected_nitrate_qc_flag\"] = qc_flags\n",
    "new_issm[\"bottle_corrected_nitrate_qc_flag\"].attrs = {\n",
    "    'flag_values': np.array([1, 2, 3, 4, 9]),\n",
    "    'flag_meanings': 'pass not_evaluated suspect_or_of_high_interest fail missing_data',\n",
    "    'standard_name': 'bottle_corrected_nitrate status_flag',\n",
    "    'long_name': 'Nitrate Concentration - Temp, Sal, and Drift Corrected Quality Flag',\n",
    "    'comment': ('This quality flag represents an assessment of the nitrate concentration '\n",
    "                'that is corrected for temperature, salinity following Sakamoto (2009), '\n",
    "                'for instrument drift, and discrete water samples collected during deployment '\n",
    "                'and recovery. Checks include assessment of RMSE of the spectral '\n",
    "                'measurements, absorptions at 254 nm and 350 nm wavelengths, dark values, '\n",
    "                'spectral averages, and a range check based on instrument calibration.')\n",
    "}\n",
    "\n",
    "# Save the bottle values used for the corrections\n",
    "issm_deploy_bottles = deploy_bottles\n",
    "issm_recover_bottles = recover_bottles\n",
    "\n",
    "# Save the results\n",
    "new_issm.to_netcdf(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/ISSM/CP03ISSM-RID26-07-NUTNRB000_bottle_corrected.nc\", format='netcdf4', engine='h5netcdf')\n",
    "smoothed_issm.to_netcdf(\"/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/ISSM/CP03ISSM-RID26-07-NUTNRB000_bottle_corrected_smoothed.nc\", format='netcdf4', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68962316-52b1-490f-ae6f-2076a06cb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all of the deployment and recovery bottles together and add their site\n",
    "ossm_deploy_bottles['Site'] = 'OSSM'\n",
    "ossm_recover_bottles['Site'] = 'OSSM'\n",
    "\n",
    "issm_deploy_bottles['Site'] = 'ISSM'\n",
    "issm_recover_bottles['Site'] = 'ISSM'\n",
    "\n",
    "cnsm_deploy_bottles['Site'] = 'CNSM'\n",
    "cnsm_recover_bottles['Site'] = 'CNSM'\n",
    "\n",
    "deployBottles = pd.concat([cnsm_deploy_bottles, issm_deploy_bottles, ossm_deploy_bottles])\n",
    "recoverBottles = pd.concat([cnsm_recover_bottles, issm_recover_bottles, ossm_recover_bottles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598d19c-73eb-4145-96dc-a65b5bdf3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the individual deployment time series against the bottle observations\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "site = 'CNSM'\n",
    "depNum = 12\n",
    "depdata = new_cnsm.where(new_cnsm.deployment == depNum, drop=True)\n",
    "smoothed_data = smoothed_cnsm.where(smoothed_cnsm.deployment == depNum, drop=True)\n",
    "dmask = (deployBottles['Site'] == site) & (deployBottles['Deployment'] == depNum) \n",
    "rmask = (recoverBottles['Site'] == site) & (recoverBottles['Deployment'] == depNum) \n",
    "\n",
    "a = '2015-11-01'\n",
    "b = '2027-11-15'\n",
    "# ax.plot(ctdbp.sel(time=slice(a,b))['time'], ctdbp.sel(time=slice(a,b))['sea_water_pressure'], marker=\".\", linestyle=\"\", color=\"tab:blue\")\n",
    "ax.plot(depdata.sel(time=slice(a,b))['time'], depdata.sel(time=slice(a,b))['corrected_nitrate_concentration'], marker='.', linestyle=\"\", color='tab:blue', label='T-S Corrected')\n",
    "ax.plot(depdata.sel(time=slice(a,b))['time'], depdata.sel(time=slice(a,b))['drift_corrected_nitrate'], marker='.', linestyle=\"\", color='tab:green', label='T-S, Drift Corrected')\n",
    "ax.plot(depdata.sel(time=slice(a,b))['time'], depdata.sel(time=slice(a,b))['bottle_corrected_nitrate'], marker='.', linestyle=\"\", color='tab:orange', label='T-S, Drift, Bottle Corrected')\n",
    "#ax.plot(smoothed_data.sel(time=slice(a,b))['time'], smoothed_data.sel(time=slice(a,b))['drift_corrected_nitrate'], marker=\".\", linestyle=\"\", color='black', label='6H Smoothed Data')\n",
    "ax.plot(deployBottles[dmask].index, deployBottles[dmask]['Discrete Nitrate [uM]'], marker='o', linestyle='', color='tab:red', markeredgecolor='black', markersize=8, label='Discrete Bottle Sample')\n",
    "ax.plot(recoverBottles[rmask].index, recoverBottles[rmask]['Discrete Nitrate [uM]'], marker='o', linestyle='', color='tab:red', markeredgecolor='black', markersize=8)\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_ylabel('Nitrate Concentration [um/L]')\n",
    "ax.set_title('Pioneer - New England Shelf Central Surface Mooring')\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf3045-e9b6-439f-aaa3-08bad525cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('../results/figures/newsletter_article_figure.png', facecolor='white', transparent=False, bbox_inches='tight', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9eaf2f-f818-4482-b4e0-c318760835ae",
   "metadata": {},
   "source": [
    "Next, implement the quality checks on the bottle_corrected_nitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfe433-d0aa-4324-baf4-359d9bb3c5af",
   "metadata": {},
   "source": [
    "---\n",
    "## Create the Final Datasets\n",
    "\n",
    "Lastly, we want to take the datasets we've constructed above, clean them up, and save only the parameters of interest to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92542c-9047-4583-a051-4be97f288a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the variables we are interested in \n",
    "save_vars = ['serial_number', 'deployment', 'sea_water_practical_salinity', 'sea_water_temperature', 'nitrate_concentration', 'nitrate_sensor_quality_flag',\n",
    "             'corrected_nitrate_concentration', 'corrected_nitrate_concentration_qc_flag', 'drift_corrected_nitrate', 'drift_corrected_nitrate_qc_flag',\n",
    "             'bottle_corrected_nitrate', 'bottle_corrected_nitrate_qc_flag', 'corrected_nitrate_concentration_mad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e830b7f-b02e-4af6-8e84-3a1377c12e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do some cleanup - cut down to only the save parameters, rename a few variables for clearer name, update some attributes,\n",
    "# and set the datatypes for a couple of the parameters that may have changed while manipulating data\n",
    "# CNSM\n",
    "cnsm_final = new_cnsm[save_vars]\n",
    "cnsm_final = cnsm_final.rename({'corrected_nitrate_concentration_mad': 'burst_median_absolute_deviation', \n",
    "                   'nitrate_sensor_quality_flag': 'nitrate_concentration_qc_flag'})\n",
    "cnsm_final['burst_median_absolute_deviation'].attrs['comment'] = ('The median absolute deviation calculated for each sampling burst.')\n",
    "cnsm_final['drift_corrected_nitrate_qc_flag'] = cnsm_final['drift_corrected_nitrate_qc_flag'].astype('int')\n",
    "cnsm_final['nitrate_concentration_qc_flag'] = cnsm_final['nitrate_concentration_qc_flag'].astype('int')\n",
    "cnsm_final['deployment'] = cnsm_final['deployment'].astype('int')\n",
    "cnsm_final['serial_number'] = cnsm_final['serial_number'].astype('int')\n",
    "\n",
    "# ISSM\n",
    "issm_final = new_issm[save_vars]\n",
    "issm_final = issm_final.rename({'corrected_nitrate_concentration_mad': 'burst_median_absolute_deviation', \n",
    "                   'nitrate_sensor_quality_flag': 'nitrate_concentration_qc_flag'})\n",
    "issm_final['burst_median_absolute_deviation'].attrs['comment'] = ('The median absolute deviation calculated for each sampling burst.')\n",
    "issm_final['drift_corrected_nitrate_qc_flag'] = issm_final['drift_corrected_nitrate_qc_flag'].astype('int')\n",
    "issm_final['nitrate_concentration_qc_flag'] = issm_final['nitrate_concentration_qc_flag'].astype('int')\n",
    "issm_final['deployment'] = issm_final['deployment'].astype('int')\n",
    "issm_final['serial_number'] = issm_final['serial_number'].astype('int')\n",
    "\n",
    "# OSSM\n",
    "ossm_final = new_ossm[save_vars]\n",
    "ossm_final = ossm_final.rename({'corrected_nitrate_concentration_mad': 'burst_median_absolute_deviation', \n",
    "                   'nitrate_sensor_quality_flag': 'nitrate_concentration_qc_flag'})\n",
    "ossm_final['burst_median_absolute_deviation'].attrs['comment'] = ('The median absolute deviation calculated for each sampling burst.')\n",
    "ossm_final['drift_corrected_nitrate_qc_flag'] = ossm_final['drift_corrected_nitrate_qc_flag'].astype('int')\n",
    "ossm_final['nitrate_concentration_qc_flag'] = ossm_final['nitrate_concentration_qc_flag'].astype('int')\n",
    "ossm_final['deployment'] = ossm_final['deployment'].astype('int')\n",
    "ossm_final['serial_number'] = ossm_final['serial_number'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6aeb2b-9b2e-4f8b-b3fc-1ca8e0443d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final versions\n",
    "cnsm_final.to_netcdf('/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/CNSM/CP01CNSM-RID26-07-NUTNRB000_final.nc', format='netcdf4', engine='h5netcdf')\n",
    "\n",
    "issm_final.to_netcdf('/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/ISSM/CP03ISSM-RID26-07-NUTNRB000_final.nc', format='netcdf4', engine='h5netcdf')\n",
    "\n",
    "ossm_final.to_netcdf('/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/OSSM/CP04OSSM-RID26-07-NUTNRB000_final.nc', format='netcdf4', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724e424-554d-4414-9b77-1239a23d1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the deployment and recovery bottle datasets\n",
    "deployBottles['Type'] = 'Deployment'\n",
    "recoverBottles['Type'] = 'Recovery'\n",
    "all_bottles = pd.concat([deployBottles, recoverBottles])\n",
    "all_bottles.to_csv('/home/jovyan/Curated_datasets/nitrate_validation/data/Pioneer-NES/Ship/Bottle_Nitrate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f50bf-4404-440b-b325-802bb90bec75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30789050-a801-4933-a022-90868ecdd84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ooi",
   "language": "python",
   "name": "ooi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
